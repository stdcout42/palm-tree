{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('KS_train_data.csv', delimiter=',')\n",
    "# df = pd.read_csv('KS_test_data.csv', delimiter=';')\n",
    "# X = df.loc[:,'f1':'f100'].values\n",
    "# y = [ bool(y) for y in df.loc[:,'loss'].values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_time_created'] = df.deadline - df.created_at\n",
    "df['delta_time_launched'] = df.deadline - df.launched_at\n",
    "df['delta_time_launched_days'] = df.delta_time_launched / 86400\n",
    "df['delta_time_created_days'] = df.delta_time_launched / 86400\n",
    "df['goal_converted_log'] = np.log(df.goal * df.fx_rate)\n",
    "df['goal_per_day'] = df['goal_converted_log'] / df['delta_time_launched']\n",
    "total_in_cat = {}\n",
    "funded_in_cat = {}\n",
    "rate_funded_cat = {}\n",
    "for x in df.category.unique():\n",
    "    total_in_cat[x] = df.loc[(df.category == x, 'project_id')].count()\n",
    "    funded_in_cat[x] = df.loc[(df.category == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_cat[x] = funded_in_cat[x] / total_in_cat[x]\n",
    "df['rate_funded_cat'] = df.apply(lambda row: rate_funded_cat[row.category], axis=1)\n",
    "df_dum = pd.get_dummies(df, columns=[\"category\"], prefix=[\"cat_typ\"] )\n",
    "df.country = df.country.fillna('NA')\n",
    "EU = ('GB', 'ES', 'FR', 'IT', 'NL', 'IS', 'CZ', 'FI', 'DE', 'IE', 'SJ', 'DK', 'SE', 'HU', 'NO', 'CY', 'CH', 'BE', \n",
    "          'LV', 'UA', 'AT', 'SI', 'LT', 'RO', 'RU', 'AX', 'MC', 'PT', 'GL', 'GR', 'SK', 'EE', 'BA', 'ME', 'LU', 'RS',\n",
    "         'PL', 'MD', 'BG', 'HR', 'MK', 'BY', 'XK', 'FO', 'MT')\n",
    "NA = ('US', 'CA', 'MX', 'CR', 'GT', 'HT', 'AG', 'JM', 'BZ', 'CU', 'SV', 'PR', 'PA', 'NI', 'DO', 'CW', 'VI', 'BB',\n",
    "         'HN', 'LC', 'TT', 'BS', 'GP', 'VC', 'DM')\n",
    "SA = ('AR', 'PE', 'SR', 'BR', 'BO', 'EC', 'CO', 'CL', 'VE', 'PY', 'GY', 'UY')\n",
    "AF = ('KE', 'MW', 'ZA', 'RW', 'LR', 'EG', 'SN', 'NG', 'TZ', 'GH', 'GQ', 'ZM', 'MG', 'ET', 'MA', 'CD', 'BF', 'UG',\n",
    "         'CI', 'DZ', 'ML', 'SD', 'ZW', 'CM', 'TN', 'NE', 'MZ', 'GN', 'SO', 'LY', 'DJ', 'GA', 'SS', 'GM', 'BJ', 'CF',\n",
    "          'CG', 'NA')\n",
    "AS = ('TH', 'ID', 'KH', 'IN', 'JP', 'TR', 'CN', 'MY', 'MN', 'IL', 'KR', 'PH', 'HK', 'SG', 'PS', 'TW', 'NP', 'IR',\n",
    "         'QA', 'VN', 'IQ', 'AE', 'LK', 'GE', 'LB', 'AM', 'KZ', 'AF', 'KP', 'BD', 'PK', 'MM', 'BT', 'JO', 'MV', 'LA',\n",
    "         'KW', 'SY', 'TJ', 'TL', 'YE', 'MO', 'KG')\n",
    "AT = ('AQ')\n",
    "OC = ('AU','NZ', 'PG', 'FJ', 'FM', 'CK', 'GU', 'NC', 'PF', 'VU' )\n",
    "UNK = ('?')\n",
    "\n",
    "def conditions(x):\n",
    "    if x in EU:\n",
    "        return \"EU\"\n",
    "    elif x in NA:\n",
    "        return \"NA\"\n",
    "    elif x in SA:\n",
    "        return \"SA\"\n",
    "    elif x in AF:\n",
    "        return \"AF\"\n",
    "    elif x in AS:\n",
    "        return \"AS\"\n",
    "    elif x in AT:\n",
    "        return \"AT\"\n",
    "    elif x in OC:\n",
    "        return \"OC\"\n",
    "    else:\n",
    "        return \"UNK\"\n",
    "\n",
    "func = np.vectorize(conditions)\n",
    "continents = func(df[\"country\"])\n",
    "df_dum[\"continents\"] = continents\n",
    "df_dum = pd.get_dummies(df_dum, columns=[\"continents\"], prefix=[\"continent_type\"])\n",
    "df_dum = pd.get_dummies(df_dum, columns=[\"country\"], prefix=[\"country_type\"])\n",
    "country_cols = []\n",
    "for x in df_dum.columns:\n",
    "    if(x[0:3] == 'cou'):\n",
    "        country_cols.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['continent_type_AF', 'continent_type_AS', 'continent_type_AT',\n",
    "       'continent_type_EU', 'continent_type_NA', 'continent_type_OC',\n",
    "       'continent_type_SA', 'continent_type_UNK',\n",
    "       'cat_typ_art', 'cat_typ_comics', 'cat_typ_crafts',\n",
    "       'cat_typ_dance', 'cat_typ_design', 'cat_typ_fashion',\n",
    "       'cat_typ_film & video', 'cat_typ_food', 'cat_typ_games',\n",
    "       'cat_typ_journalism', 'cat_typ_music', 'cat_typ_photography',\n",
    "       'cat_typ_publishing', 'cat_typ_technology', 'cat_typ_theater', \n",
    "        'rate_funded_cat', 'delta_time_launched_days', 'goal_converted_log', 'staff_pick']\n",
    "for x in country_cols:\n",
    "    cols.append(x)\n",
    "df_try = df_dum[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_try\n",
    "y = df['funded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contigency_matrix(true_y, predicted_y):\n",
    "    # YOUR CODE HERE, Create TP, FP, TN, FN\n",
    "    tp=fp=tn=fn=0\n",
    "    for true, pred in zip(true_y, predicted_y):\n",
    "        if pred == True:\n",
    "            if pred == true:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if pred == true:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1      \n",
    "    matrix = np.array(([tp, fp], [tn, fn]))\n",
    "    # Make sure your output fits the following format:\n",
    "    # matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    return matrix\n",
    "\n",
    "def accuracy(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp+fn+tn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "        return accuracy\n",
    "def precision(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "        return precision\n",
    "def recall(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "        return recall\n",
    "def f1(true_y, predicted_y):\n",
    "    precision_v = precision(true_y, predicted_y)\n",
    "    recall_v = recall(true_y, predicted_y)\n",
    "    if precision_v+recall_v == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        f1 = 2*((precision_v*recall_v)/(precision_v+recall_v))\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>recall_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.706200</td>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.764176</td>\n",
       "      <td>0.721628</td>\n",
       "      <td>0.719997</td>\n",
       "      <td>0.821128</td>\n",
       "      <td>0.814131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.769638</td>\n",
       "      <td>0.767237</td>\n",
       "      <td>0.723160</td>\n",
       "      <td>0.724204</td>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.815708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.710911</td>\n",
       "      <td>0.769392</td>\n",
       "      <td>0.767298</td>\n",
       "      <td>0.724054</td>\n",
       "      <td>0.724761</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>0.815138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.7127</td>\n",
       "      <td>0.711056</td>\n",
       "      <td>0.769033</td>\n",
       "      <td>0.767395</td>\n",
       "      <td>0.723820</td>\n",
       "      <td>0.724905</td>\n",
       "      <td>0.820271</td>\n",
       "      <td>0.815176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.710967</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.767294</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.820271</td>\n",
       "      <td>0.814967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.710967</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.767294</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.820271</td>\n",
       "      <td>0.814967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.710967</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.767294</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.820271</td>\n",
       "      <td>0.814967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.710967</td>\n",
       "      <td>0.769157</td>\n",
       "      <td>0.767294</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.820271</td>\n",
       "      <td>0.814967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_test  accuracy_train   f1_test  f1_train  precision_test  \\\n",
       "C-value                                                                        \n",
       "0.0001            0.7110        0.706200  0.768169  0.764176        0.721628   \n",
       "0.0010            0.7129        0.710611  0.769638  0.767237        0.723160   \n",
       "0.0100            0.7131        0.710911  0.769392  0.767298        0.724054   \n",
       "0.1000            0.7127        0.711056  0.769033  0.767395        0.723820   \n",
       "1.0000            0.7129        0.710967  0.769157  0.767294        0.724039   \n",
       "10.0000           0.7129        0.710967  0.769157  0.767294        0.724039   \n",
       "100.0000          0.7129        0.710967  0.769157  0.767294        0.724039   \n",
       "1000.0000         0.7129        0.710967  0.769157  0.767294        0.724039   \n",
       "\n",
       "           precision_train  recall_test  recall_train  \n",
       "C-value                                                \n",
       "0.0001            0.719997     0.821128      0.814131  \n",
       "0.0010            0.724204     0.822500      0.815708  \n",
       "0.0100            0.724761     0.820785      0.815138  \n",
       "0.1000            0.724905     0.820271      0.815176  \n",
       "1.0000            0.724891     0.820271      0.814967  \n",
       "10.0000           0.724891     0.820271      0.814967  \n",
       "100.0000          0.724891     0.820271      0.814967  \n",
       "1000.0000         0.724891     0.820271      0.814967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.1)\n",
    "imp_median_X = SimpleImputer(missing_values=np.nan, strategy='median').fit(X_train)\n",
    "X_train = imp_median_X.transform(X_train)\n",
    "X_test = imp_median_X.transform(X_test)\n",
    "\n",
    "imp_median_y = SimpleImputer(missing_values=np.nan, strategy='median').fit(y_train)\n",
    "y_train = imp_median_y.transform(y_train)\n",
    "y_test = imp_median_y.transform(y_test)\n",
    "\n",
    "# fit scaler and scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "def compute_scores(X_train,X_test,y_train,y_test, C):\n",
    "    # fit logistic regression model\n",
    "    logreg = LogisticRegression(C=C, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "    # predict y for train set\n",
    "    pred_train = logreg.predict(X_train).tolist()\n",
    "    # predict y for test set\n",
    "    pred_test = logreg.predict(X_test).tolist()\n",
    "            \n",
    "    # calculate evaluation measures\n",
    "    evaluation_measures = dict()\n",
    "    evaluation_measures['accuracy_train'] = accuracy(y_train, pred_train)\n",
    "    evaluation_measures['accuracy_test'] = accuracy(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['precision_train'] = precision(y_train, pred_train)\n",
    "    evaluation_measures['precision_test'] = precision(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['recall_train'] = recall(y_train, pred_train)\n",
    "    evaluation_measures['recall_test'] = recall(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['f1_train'] = f1(y_train, pred_train)\n",
    "    evaluation_measures['f1_test'] = f1(y_test, pred_test)\n",
    "    \n",
    "    return evaluation_measures\n",
    "    \n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "measures = pd.DataFrame()\n",
    "for c in C:\n",
    "    em = compute_scores(X_train_scaled,X_test_scaled,y_train,y_test, c)\n",
    "    em = pd.Series(em)\n",
    "    measures = measures.append(em, ignore_index=True)\n",
    "measures.index = C\n",
    "measures.index = measures.index.rename('C-value')\n",
    "display(measures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42892, 16297],\n",
       "       [21080,  9731]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "pred_train = logreg.predict(X_train).tolist()\n",
    "contigency_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def upsample(y_train):\n",
    "    # y_train is the 1d matrix of the labels in your training data, e.g.\n",
    "    #       0     1     2     3     4   5     6     7     8   ... \n",
    "    # y = [True False False False True True False False False ... False]\n",
    "    #\n",
    "    # the function returns the position of the training data to be considered for the final training set.\n",
    "    # e.g. if you decide from the True instances to select 0, 4 and 5, while from the False instances 1, 3, and 8\n",
    "    # the outcome of the function will be [0, 1, 3, 4, 5, 8] (= sampled_indexes)\n",
    "    falses = 0\n",
    "    false_indexes = []\n",
    "    true_indexes = []\n",
    "    for index, value in enumerate(y_train):\n",
    "        if value == False:\n",
    "            falses += 1\n",
    "            false_indexes.append(index)\n",
    "        else:\n",
    "            true_indexes.append(index)\n",
    "    sampled_indexes = random.sample(true_indexes, falses) + false_indexes\n",
    "\n",
    "    return sampled_indexes\n",
    "    \n",
    "def new_training_set(X_train, y_train, sampled_indexes):\n",
    "    X_train_new = []\n",
    "    y_train_new = []\n",
    "    for index in sampled_indexes:\n",
    "        X_train_new.append(X_train[index])\n",
    "        y_train_new.append(y_train[index])\n",
    "    return [np.array(X_train_new), np.array(y_train_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>recall_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.7020</td>\n",
       "      <td>0.688670</td>\n",
       "      <td>0.738780</td>\n",
       "      <td>0.692709</td>\n",
       "      <td>0.758186</td>\n",
       "      <td>0.683838</td>\n",
       "      <td>0.720342</td>\n",
       "      <td>0.701813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.6990</td>\n",
       "      <td>0.691585</td>\n",
       "      <td>0.732872</td>\n",
       "      <td>0.693164</td>\n",
       "      <td>0.762089</td>\n",
       "      <td>0.689632</td>\n",
       "      <td>0.705812</td>\n",
       "      <td>0.696732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.733020</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>0.762609</td>\n",
       "      <td>0.690123</td>\n",
       "      <td>0.705641</td>\n",
       "      <td>0.695235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.691718</td>\n",
       "      <td>0.733197</td>\n",
       "      <td>0.692749</td>\n",
       "      <td>0.762793</td>\n",
       "      <td>0.690440</td>\n",
       "      <td>0.705812</td>\n",
       "      <td>0.695074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.691718</td>\n",
       "      <td>0.733197</td>\n",
       "      <td>0.692749</td>\n",
       "      <td>0.762793</td>\n",
       "      <td>0.690440</td>\n",
       "      <td>0.705812</td>\n",
       "      <td>0.695074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.691718</td>\n",
       "      <td>0.733197</td>\n",
       "      <td>0.692749</td>\n",
       "      <td>0.762793</td>\n",
       "      <td>0.690440</td>\n",
       "      <td>0.705812</td>\n",
       "      <td>0.695074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.691732</td>\n",
       "      <td>0.733197</td>\n",
       "      <td>0.692775</td>\n",
       "      <td>0.762793</td>\n",
       "      <td>0.690438</td>\n",
       "      <td>0.705812</td>\n",
       "      <td>0.695128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.691732</td>\n",
       "      <td>0.733197</td>\n",
       "      <td>0.692775</td>\n",
       "      <td>0.762793</td>\n",
       "      <td>0.690438</td>\n",
       "      <td>0.705812</td>\n",
       "      <td>0.695128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_test  accuracy_train   f1_test  f1_train  precision_test  \\\n",
       "C-value                                                                        \n",
       "0.0001            0.7020        0.688670  0.738780  0.692709        0.758186   \n",
       "0.0010            0.6990        0.691585  0.732872  0.693164        0.762089   \n",
       "0.0100            0.6993        0.691531  0.733020  0.692669        0.762609   \n",
       "0.1000            0.6995        0.691718  0.733197  0.692749        0.762793   \n",
       "1.0000            0.6995        0.691718  0.733197  0.692749        0.762793   \n",
       "10.0000           0.6995        0.691718  0.733197  0.692749        0.762793   \n",
       "100.0000          0.6995        0.691732  0.733197  0.692775        0.762793   \n",
       "1000.0000         0.6995        0.691732  0.733197  0.692775        0.762793   \n",
       "\n",
       "           precision_train  recall_test  recall_train  \n",
       "C-value                                                \n",
       "0.0001            0.683838     0.720342      0.701813  \n",
       "0.0010            0.689632     0.705812      0.696732  \n",
       "0.0100            0.690123     0.705641      0.695235  \n",
       "0.1000            0.690440     0.705812      0.695074  \n",
       "1.0000            0.690440     0.705812      0.695074  \n",
       "10.0000           0.690440     0.705812      0.695074  \n",
       "100.0000          0.690438     0.705812      0.695128  \n",
       "1000.0000         0.690438     0.705812      0.695128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_indexes = upsample(y_train)\n",
    "v = new_training_set(X_train_scaled, y_train, sampled_indexes)\n",
    "X_train_up = v[0]\n",
    "y_train_up = v[1]\n",
    "\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "measures = pd.DataFrame()\n",
    "for c in C:\n",
    "    em = compute_scores(X_train_up,X_test_scaled,y_train_up,y_test, c)\n",
    "    em = pd.Series(em)\n",
    "    measures = measures.append(em, ignore_index=True)\n",
    "measures.index = C\n",
    "measures.index = measures.index.rename('C-value')\n",
    "display(measures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.1)\n",
    "imp_median_X = SimpleImputer(missing_values=np.nan, strategy='median').fit(X_train)\n",
    "X_train = imp_median_X.transform(X_train)\n",
    "X_test = imp_median_X.transform(X_test)\n",
    "\n",
    "imp_median_y = SimpleImputer(missing_values=np.nan, strategy='median').fit(y_train)\n",
    "y_train = imp_median_y.transform(y_train)\n",
    "y_test = imp_median_y.transform(y_test)\n",
    "\n",
    "# fit scaler and scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# upsamle training data\n",
    "sampled_indexes = upsample(y_train)\n",
    "v = new_training_set(X_train_scaled, y_train, sampled_indexes)\n",
    "X_train_up = v[0]\n",
    "y_train_up = v[1]\n",
    "\n",
    "def compute_scores_neural(X_train,X_test,y_train,y_test, layers, activation_func):\n",
    "    # fit neural network model\n",
    "    mlp = MLPClassifier(max_iter=10000, hidden_layer_sizes=layers, activation=activation_func).fit(X_train, y_train.ravel())\n",
    "    # predict y for train set\n",
    "    pred_train = mlp.predict(X_train).tolist()\n",
    "    # predict y for test set\n",
    "    pred_test = mlp.predict(X_test).tolist()\n",
    "            \n",
    "    # calculate evaluation measures\n",
    "    evaluation_measures = dict()\n",
    "    evaluation_measures['accuracy_train'] = accuracy(y_train, pred_train)\n",
    "    evaluation_measures['accuracy_test'] = accuracy(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['precision_train'] = precision(y_train, pred_train)\n",
    "    evaluation_measures['precision_test'] = precision(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['recall_train'] = recall(y_train, pred_train)\n",
    "    evaluation_measures['recall_test'] = recall(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['f1_train'] = f1(y_train, pred_train)\n",
    "    evaluation_measures['f1_test'] = f1(y_test, pred_test)\n",
    "    \n",
    "    return evaluation_measures\n",
    "\n",
    "# create df\n",
    "layers = [[30],[30,30],[30,30,30],[100], [100,100],[100,100,100],[200],[200,200],[200,200,200]]\n",
    "activation_functions = ['logistic', 'tanh', 'relu']\n",
    "measuresDict = dict()\n",
    "for layer in layers:\n",
    "    for activation_func in activation_functions:\n",
    "        em = compute_scores_neural(X_train_up,X_test_scaled,y_train_up,y_test, layer, activation_func)\n",
    "        if activation_func not in measuresDict.keys():\n",
    "            measuresDict[activation_func] = {layer[0]:{len(layer): em.values()}}\n",
    "        else:\n",
    "            if layer[0] not in measuresDict[activation_func].keys():\n",
    "                measuresDict[activation_func][layer[0]] = {len(layer): em.values()}\n",
    "            else:\n",
    "                measuresDict[activation_func][layer[0]][len(layer)]= em.values()\n",
    "\n",
    "measures_ordered = {(activ_func, nodes, layers): list(values)\n",
    "    for activ_func, nodes in measuresDict.items()\n",
    "    for nodes, layers in nodes.items()\n",
    "    for layers, values in layers.items()}\n",
    "measures = pd.DataFrame(measures_ordered)\n",
    "measures = measures.T\n",
    "measures.columns = em.keys()\n",
    "measures.index.set_names(['activation function', 'nodes per layer', 'layers'], inplace=True)\n",
    "display(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
