{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('KS_train_data.csv', delimiter=',')\n",
    "# df = pd.read_csv('KS_test_data.csv', delimiter=';')\n",
    "# X = df.loc[:,'f1':'f100'].values\n",
    "# y = [ bool(y) for y in df.loc[:,'loss'].values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_time_created'] = df.deadline - df.created_at\n",
    "df['delta_time_launched'] = df.deadline - df.launched_at\n",
    "df['delta_time_launched_days'] = df.delta_time_launched / 86400\n",
    "df['delta_time_created_days'] = df.delta_time_launched / 86400\n",
    "df['goal_converted_log'] = np.log(df.goal * df.fx_rate)\n",
    "df['goal_per_day'] = df['goal_converted_log'] / df['delta_time_launched']\n",
    "total_in_cat = {}\n",
    "funded_in_cat = {}\n",
    "rate_funded_cat = {}\n",
    "for x in df.category.unique():\n",
    "    total_in_cat[x] = df.loc[(df.category == x, 'project_id')].count()\n",
    "    funded_in_cat[x] = df.loc[(df.category == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_cat[x] = funded_in_cat[x] / total_in_cat[x]\n",
    "df['rate_funded_cat'] = df.apply(lambda row: rate_funded_cat[row.category], axis=1)\n",
    "df_dum = pd.get_dummies(df, columns=[\"category\"], prefix=[\"cat_typ\"] )\n",
    "df.country = df.country.fillna('NA')\n",
    "EU = ('GB', 'ES', 'FR', 'IT', 'NL', 'IS', 'CZ', 'FI', 'DE', 'IE', 'SJ', 'DK', 'SE', 'HU', 'NO', 'CY', 'CH', 'BE', \n",
    "          'LV', 'UA', 'AT', 'SI', 'LT', 'RO', 'RU', 'AX', 'MC', 'PT', 'GL', 'GR', 'SK', 'EE', 'BA', 'ME', 'LU', 'RS',\n",
    "         'PL', 'MD', 'BG', 'HR', 'MK', 'BY', 'XK', 'FO', 'MT')\n",
    "NA = ('US', 'CA', 'MX', 'CR', 'GT', 'HT', 'AG', 'JM', 'BZ', 'CU', 'SV', 'PR', 'PA', 'NI', 'DO', 'CW', 'VI', 'BB',\n",
    "         'HN', 'LC', 'TT', 'BS', 'GP', 'VC', 'DM')\n",
    "SA = ('AR', 'PE', 'SR', 'BR', 'BO', 'EC', 'CO', 'CL', 'VE', 'PY', 'GY', 'UY')\n",
    "AF = ('KE', 'MW', 'ZA', 'RW', 'LR', 'EG', 'SN', 'NG', 'TZ', 'GH', 'GQ', 'ZM', 'MG', 'ET', 'MA', 'CD', 'BF', 'UG',\n",
    "         'CI', 'DZ', 'ML', 'SD', 'ZW', 'CM', 'TN', 'NE', 'MZ', 'GN', 'SO', 'LY', 'DJ', 'GA', 'SS', 'GM', 'BJ', 'CF',\n",
    "          'CG', 'NA')\n",
    "AS = ('TH', 'ID', 'KH', 'IN', 'JP', 'TR', 'CN', 'MY', 'MN', 'IL', 'KR', 'PH', 'HK', 'SG', 'PS', 'TW', 'NP', 'IR',\n",
    "         'QA', 'VN', 'IQ', 'AE', 'LK', 'GE', 'LB', 'AM', 'KZ', 'AF', 'KP', 'BD', 'PK', 'MM', 'BT', 'JO', 'MV', 'LA',\n",
    "         'KW', 'SY', 'TJ', 'TL', 'YE', 'MO', 'KG')\n",
    "AT = ('AQ')\n",
    "OC = ('AU','NZ', 'PG', 'FJ', 'FM', 'CK', 'GU', 'NC', 'PF', 'VU' )\n",
    "UNK = ('?')\n",
    "\n",
    "def conditions(x):\n",
    "    if x in EU:\n",
    "        return \"EU\"\n",
    "    elif x in NA:\n",
    "        return \"NA\"\n",
    "    elif x in SA:\n",
    "        return \"SA\"\n",
    "    elif x in AF:\n",
    "        return \"AF\"\n",
    "    elif x in AS:\n",
    "        return \"AS\"\n",
    "    elif x in AT:\n",
    "        return \"AT\"\n",
    "    elif x in OC:\n",
    "        return \"OC\"\n",
    "    else:\n",
    "        return \"UNK\"\n",
    "\n",
    "func = np.vectorize(conditions)\n",
    "continents = func(df[\"country\"])\n",
    "df_dum[\"continents\"] = continents\n",
    "df_dum = pd.get_dummies(df_dum, columns=[\"continents\"], prefix=[\"continent_type\"])\n",
    "df_dum = pd.get_dummies(df_dum, columns=[\"country\"], prefix=[\"country_type\"])\n",
    "country_cols = []\n",
    "for x in df_dum.columns:\n",
    "    if(x[0:3] == 'cou'):\n",
    "        country_cols.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['continent_type_AF', 'continent_type_AS', 'continent_type_AT',\n",
    "       'continent_type_EU', 'continent_type_NA', 'continent_type_OC',\n",
    "       'continent_type_SA', 'continent_type_UNK',\n",
    "       'cat_typ_art', 'cat_typ_comics', 'cat_typ_crafts',\n",
    "       'cat_typ_dance', 'cat_typ_design', 'cat_typ_fashion',\n",
    "       'cat_typ_film & video', 'cat_typ_food', 'cat_typ_games',\n",
    "       'cat_typ_journalism', 'cat_typ_music', 'cat_typ_photography',\n",
    "       'cat_typ_publishing', 'cat_typ_technology', 'cat_typ_theater', \n",
    "        'rate_funded_cat', 'delta_time_launched_days', 'goal_converted_log', 'staff_pick']\n",
    "for x in country_cols:\n",
    "    cols.append(x)\n",
    "df_try = df_dum[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_try\n",
    "y = df['funded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contigency_matrix(true_y, predicted_y):\n",
    "    # YOUR CODE HERE, Create TP, FP, TN, FN\n",
    "    tp=fp=tn=fn=0\n",
    "    for true, pred in zip(true_y, predicted_y):\n",
    "        if pred == True:\n",
    "            if pred == true:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if pred == true:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1      \n",
    "    matrix = np.array(([tp, fp], [tn, fn]))\n",
    "    # Make sure your output fits the following format:\n",
    "    # matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    return matrix\n",
    "\n",
    "def accuracy(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp+fn+tn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "        return accuracy\n",
    "def precision(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "        return precision\n",
    "def recall(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "        return recall\n",
    "def f1(true_y, predicted_y):\n",
    "    precision_v = precision(true_y, predicted_y)\n",
    "    recall_v = recall(true_y, predicted_y)\n",
    "    if precision_v+recall_v == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        f1 = 2*((precision_v*recall_v)/(precision_v+recall_v))\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(X, degree):\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    ### END SOLUTION\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>recall_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.70756</td>\n",
       "      <td>0.705760</td>\n",
       "      <td>0.765951</td>\n",
       "      <td>0.763457</td>\n",
       "      <td>0.720967</td>\n",
       "      <td>0.719687</td>\n",
       "      <td>0.816922</td>\n",
       "      <td>0.812897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.71032</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>0.767944</td>\n",
       "      <td>0.766901</td>\n",
       "      <td>0.723436</td>\n",
       "      <td>0.724166</td>\n",
       "      <td>0.818287</td>\n",
       "      <td>0.814997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.71068</td>\n",
       "      <td>0.711293</td>\n",
       "      <td>0.767928</td>\n",
       "      <td>0.767210</td>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.725150</td>\n",
       "      <td>0.817195</td>\n",
       "      <td>0.814449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.71080</td>\n",
       "      <td>0.711573</td>\n",
       "      <td>0.767927</td>\n",
       "      <td>0.767373</td>\n",
       "      <td>0.724531</td>\n",
       "      <td>0.725478</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.814403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.71080</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.767927</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.724531</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.814312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.71076</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.767888</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.724514</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.816785</td>\n",
       "      <td>0.814312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.71076</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.767888</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.724514</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.816785</td>\n",
       "      <td>0.814312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>0.71076</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.767888</td>\n",
       "      <td>0.767312</td>\n",
       "      <td>0.724514</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.816785</td>\n",
       "      <td>0.814312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy_test  accuracy_train   f1_test  f1_train  precision_test  \\\n",
       "C-value                                                                        \n",
       "0.0001           0.70756        0.705760  0.765951  0.763457        0.720967   \n",
       "0.0010           0.71032        0.710600  0.767944  0.766901        0.723436   \n",
       "0.0100           0.71068        0.711293  0.767928  0.767210        0.724263   \n",
       "0.1000           0.71080        0.711573  0.767927  0.767373        0.724531   \n",
       "1.0000           0.71080        0.711507  0.767927  0.767312        0.724531   \n",
       "10.0000          0.71076        0.711507  0.767888  0.767312        0.724514   \n",
       "100.0000         0.71076        0.711507  0.767888  0.767312        0.724514   \n",
       "1000.0000        0.71076        0.711507  0.767888  0.767312        0.724514   \n",
       "\n",
       "           precision_train  recall_test  recall_train  \n",
       "C-value                                                \n",
       "0.0001            0.719687     0.816922      0.812897  \n",
       "0.0010            0.724166     0.818287      0.814997  \n",
       "0.0100            0.725150     0.817195      0.814449  \n",
       "0.1000            0.725478     0.816853      0.814403  \n",
       "1.0000            0.725441     0.816853      0.814312  \n",
       "10.0000           0.725441     0.816785      0.814312  \n",
       "100.0000          0.725441     0.816785      0.814312  \n",
       "1000.0000         0.725441     0.816785      0.814312  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.25)\n",
    "imp_median_X = SimpleImputer(missing_values=np.nan, strategy='median').fit(X_train)\n",
    "X_train = imp_median_X.transform(X_train)\n",
    "X_test = imp_median_X.transform(X_test)\n",
    "\n",
    "imp_median_y = SimpleImputer(missing_values=np.nan, strategy='median').fit(y_train)\n",
    "y_train = imp_median_y.transform(y_train)\n",
    "y_test = imp_median_y.transform(y_test)\n",
    "\n",
    "# fit scaler and scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "def compute_scores(X_train,X_test,y_train,y_test, C):\n",
    "    # fit logistic regression model\n",
    "    logreg = LogisticRegression(C=C, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "    # predict y for train set\n",
    "    pred_train = logreg.predict(X_train).tolist()\n",
    "    # predict y for test set\n",
    "    pred_test = logreg.predict(X_test).tolist()\n",
    "            \n",
    "    # calculate evaluation measures\n",
    "    evaluation_measures = dict()\n",
    "    evaluation_measures['accuracy_train'] = accuracy(y_train, pred_train)\n",
    "    evaluation_measures['accuracy_test'] = accuracy(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['precision_train'] = precision(y_train, pred_train)\n",
    "    evaluation_measures['precision_test'] = precision(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['recall_train'] = recall(y_train, pred_train)\n",
    "    evaluation_measures['recall_test'] = recall(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['f1_train'] = f1(y_train, pred_train)\n",
    "    evaluation_measures['f1_test'] = f1(y_test, pred_test)\n",
    "    \n",
    "    return evaluation_measures\n",
    "\n",
    "# for power in [1, 2]:\n",
    "#     X_train_poly = polynomial(X_train, power)\n",
    "#     X_test_poly = polynomial(X_test, power)\n",
    "# # Scale all features using the RobustScaler\n",
    "# scaler = RobustScaler().fit(X_train_poly)\n",
    "# X_train_scaled = scaler.transform(X_train_poly)\n",
    "# X_test_scaled = scaler.transform(X_test_poly)\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "measures = pd.DataFrame()\n",
    "for c in C:\n",
    "    em = compute_scores(X_train_scaled,X_test_scaled,y_train,y_test, c)\n",
    "    em = pd.Series(em)\n",
    "    measures = measures.append(em, ignore_index=True)\n",
    "measures.index = C\n",
    "measures.index = measures.index.rename('C-value')\n",
    "display(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35677, 13510],\n",
       "       [17680,  8133]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "pred_train = logreg.predict(X_train).tolist()\n",
    "contigency_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
