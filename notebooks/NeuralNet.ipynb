{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('KS_train_data.csv', delimiter=',')\n",
    "# df = pd.read_csv('KS_test_data.csv', delimiter=';')\n",
    "# X = df.loc[:,'f1':'f100'].values\n",
    "# y = [ bool(y) for y in df.loc[:,'loss'].values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country = df.country.fillna('NA')\n",
    "EU = ('GB', 'ES', 'FR', 'IT', 'NL', 'IS', 'CZ', 'FI', 'DE', 'IE', 'SJ', 'DK', 'SE', 'HU', 'NO', 'CY', 'CH', 'BE', \n",
    "          'LV', 'UA', 'AT', 'SI', 'LT', 'RO', 'RU', 'AX', 'MC', 'PT', 'GL', 'GR', 'SK', 'EE', 'BA', 'ME', 'LU', 'RS',\n",
    "         'PL', 'MD', 'BG', 'HR', 'MK', 'BY', 'XK', 'FO', 'MT')\n",
    "NA = ('US', 'CA', 'MX', 'CR', 'GT', 'HT', 'AG', 'JM', 'BZ', 'CU', 'SV', 'PR', 'PA', 'NI', 'DO', 'CW', 'VI', 'BB',\n",
    "         'HN', 'LC', 'TT', 'BS', 'GP', 'VC', 'DM')\n",
    "SA = ('AR', 'PE', 'SR', 'BR', 'BO', 'EC', 'CO', 'CL', 'VE', 'PY', 'GY', 'UY')\n",
    "AF = ('KE', 'MW', 'ZA', 'RW', 'LR', 'EG', 'SN', 'NG', 'TZ', 'GH', 'GQ', 'ZM', 'MG', 'ET', 'MA', 'CD', 'BF', 'UG',\n",
    "         'CI', 'DZ', 'ML', 'SD', 'ZW', 'CM', 'TN', 'NE', 'MZ', 'GN', 'SO', 'LY', 'DJ', 'GA', 'SS', 'GM', 'BJ', 'CF',\n",
    "          'CG', 'NA')\n",
    "AS = ('TH', 'ID', 'KH', 'IN', 'JP', 'TR', 'CN', 'MY', 'MN', 'IL', 'KR', 'PH', 'HK', 'SG', 'PS', 'TW', 'NP', 'IR',\n",
    "         'QA', 'VN', 'IQ', 'AE', 'LK', 'GE', 'LB', 'AM', 'KZ', 'AF', 'KP', 'BD', 'PK', 'MM', 'BT', 'JO', 'MV', 'LA',\n",
    "         'KW', 'SY', 'TJ', 'TL', 'YE', 'MO', 'KG')\n",
    "AT = ('AQ')\n",
    "OC = ('AU','NZ', 'PG', 'FJ', 'FM', 'CK', 'GU', 'NC', 'PF', 'VU' )\n",
    "UNK = ('?')\n",
    "def conditions(x):\n",
    "    if x in EU:\n",
    "        return \"EU\"\n",
    "    elif x in NA:\n",
    "        return \"NA\"\n",
    "    elif x in SA:\n",
    "        return \"SA\"\n",
    "    elif x in AF:\n",
    "        return \"AF\"\n",
    "    elif x in AS:\n",
    "        return \"AS\"\n",
    "    elif x in AT:\n",
    "        return \"AT\"\n",
    "    elif x in OC:\n",
    "        return \"OC\"\n",
    "    else:\n",
    "        return \"UNK\"\n",
    "\n",
    "func = np.vectorize(conditions)\n",
    "continents = func(df[\"country\"])\n",
    "df[\"continent\"] = continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_cat = {}\n",
    "funded_in_cat = {}\n",
    "rate_funded_cat = {}\n",
    "for x in df.category.unique():\n",
    "    total_in_cat[x] = df.loc[(df.category == x, 'project_id')].count()\n",
    "    funded_in_cat[x] = df.loc[(df.category == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_cat[x] = funded_in_cat[x] / total_in_cat[x]\n",
    "df['rate_funded_cat'] = df.apply(lambda row: rate_funded_cat[row.category], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_country = {}\n",
    "funded_in_country = {}\n",
    "rate_funded_country = {}\n",
    "for x in df.country.unique():\n",
    "    total_in_country[x] = df.loc[(df.country == x, 'project_id')].count()\n",
    "    funded_in_country[x] = df.loc[(df.country == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_country[x] = funded_in_country[x] / total_in_country[x]\n",
    "df['rate_funded_country'] = df.apply(lambda row: rate_funded_country[row.country], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_continent = {}\n",
    "funded_in_continent = {}\n",
    "rate_funded_continent = {}\n",
    "for x in df.continent.unique():\n",
    "    total_in_continent[x] = df.loc[(df.continent == x, 'project_id')].count()\n",
    "    funded_in_continent[x] = df.loc[(df.continent == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_continent[x] = funded_in_continent[x] / total_in_continent[x]\n",
    "df['rate_funded_continent'] = df.apply(lambda row: rate_funded_continent[row.continent], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_sub = {}\n",
    "funded_in_sub = {}\n",
    "rate_funded_sub = {}\n",
    "for x in df.subcategory.unique():\n",
    "    total_in_sub[x] = df.loc[(df.subcategory == x, 'project_id')].count()\n",
    "    funded_in_sub[x] = df.loc[(df.subcategory == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_sub[x] = funded_in_sub[x] / total_in_sub[x]\n",
    "df['rate_funded_sub'] = df.apply(lambda row: rate_funded_sub[row.subcategory], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_time_created'] = df.deadline - df.created_at\n",
    "df['delta_time_launched'] = df.deadline - df.launched_at\n",
    "df['delta_time_launched_days'] = df.delta_time_launched / 86400\n",
    "df['delta_time_created_days'] = df.delta_time_launched / 86400\n",
    "df['goal_converted_log'] = np.log(df.goal * df.fx_rate)\n",
    "df['goal_per_day'] = df['goal_converted_log'] / df['delta_time_launched']\n",
    "cols = ['rate_funded_sub','rate_funded_continent', 'rate_funded_cat', \n",
    "        'delta_time_launched_days', 'goal_converted_log', 'staff_pick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_id', 'backers_count', 'blurb', 'category',\n",
       "       'converted_pledged_amount', 'country', 'created_at', 'currency',\n",
       "       'deadline', 'fx_rate',\n",
       "       ...\n",
       "       'tour', 'up', 'us', 'video', 'we', 'web', 'with', 'world', 'you',\n",
       "       'your'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy as sp\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.max_features = 100\n",
    "vectorizer.max_df = .5\n",
    "\n",
    "\n",
    "# vectorizer.min_df = 0.01\n",
    "# vectorizer.fit(new_df.name.astype('U'))\n",
    "# new_ = sp.sparse.hstack( (vectorizer.transform(df.name.astype('U')),\n",
    "#                  df[cols].values.astype(np.float)), format='csr')\n",
    "\n",
    "# new_columns = vectorizer.get_feature_names() + df[cols].columns.tolist()\n",
    "X = vectorizer.fit_transform(new_df.name.astype('U')) \n",
    "count_vect_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n",
    "new_df = pd.concat([new_df, count_vect_df], axis=1)\n",
    "new_df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vectorizer.get_feature_names():\n",
    "    cols.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[cols]\n",
    "y = new_df['funded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contigency_matrix(true_y, predicted_y):\n",
    "    # YOUR CODE HERE, Create TP, FP, TN, FN\n",
    "    tp=fp=tn=fn=0\n",
    "    for true, pred in zip(true_y, predicted_y):\n",
    "        if pred == True:\n",
    "            if pred == true:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if pred == true:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1      \n",
    "    matrix = np.array(([tp, fp], [tn, fn]))\n",
    "    # Make sure your output fits the following format:\n",
    "    # matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    return matrix\n",
    "\n",
    "def accuracy(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp+fn+tn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "        return accuracy\n",
    "def precision(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "        return precision\n",
    "def recall(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "        return recall\n",
    "def f1(true_y, predicted_y):\n",
    "    precision_v = precision(true_y, predicted_y)\n",
    "    recall_v = recall(true_y, predicted_y)\n",
    "    if precision_v+recall_v == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        f1 = 2*((precision_v*recall_v)/(precision_v+recall_v))\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(X, degree):\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    ### END SOLUTION\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>recall_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.78264</td>\n",
       "      <td>0.783907</td>\n",
       "      <td>0.811529</td>\n",
       "      <td>0.812352</td>\n",
       "      <td>0.823815</td>\n",
       "      <td>0.824543</td>\n",
       "      <td>0.799604</td>\n",
       "      <td>0.800516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.78996</td>\n",
       "      <td>0.791587</td>\n",
       "      <td>0.819224</td>\n",
       "      <td>0.820579</td>\n",
       "      <td>0.825333</td>\n",
       "      <td>0.825573</td>\n",
       "      <td>0.813205</td>\n",
       "      <td>0.815645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.78952</td>\n",
       "      <td>0.791800</td>\n",
       "      <td>0.819374</td>\n",
       "      <td>0.821210</td>\n",
       "      <td>0.823047</td>\n",
       "      <td>0.824126</td>\n",
       "      <td>0.815734</td>\n",
       "      <td>0.818315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.78932</td>\n",
       "      <td>0.791880</td>\n",
       "      <td>0.819270</td>\n",
       "      <td>0.821389</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>0.823793</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.818999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.78924</td>\n",
       "      <td>0.791867</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.821384</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.823759</td>\n",
       "      <td>0.815870</td>\n",
       "      <td>0.819022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.78924</td>\n",
       "      <td>0.791853</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.821370</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.823755</td>\n",
       "      <td>0.815870</td>\n",
       "      <td>0.818999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.78924</td>\n",
       "      <td>0.791840</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.821361</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.823736</td>\n",
       "      <td>0.815870</td>\n",
       "      <td>0.818999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>0.78924</td>\n",
       "      <td>0.791840</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.821361</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.823736</td>\n",
       "      <td>0.815870</td>\n",
       "      <td>0.818999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0000</th>\n",
       "      <td>0.78924</td>\n",
       "      <td>0.791840</td>\n",
       "      <td>0.819202</td>\n",
       "      <td>0.821361</td>\n",
       "      <td>0.822561</td>\n",
       "      <td>0.823736</td>\n",
       "      <td>0.815870</td>\n",
       "      <td>0.818999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy_test  accuracy_train   f1_test  f1_train  precision_test  \\\n",
       "C-value                                                                         \n",
       "0.0001            0.78264        0.783907  0.811529  0.812352        0.823815   \n",
       "0.0010            0.78996        0.791587  0.819224  0.820579        0.825333   \n",
       "0.0100            0.78952        0.791800  0.819374  0.821210        0.823047   \n",
       "0.1000            0.78932        0.791880  0.819270  0.821389        0.822630   \n",
       "1.0000            0.78924        0.791867  0.819202  0.821384        0.822561   \n",
       "10.0000           0.78924        0.791853  0.819202  0.821370        0.822561   \n",
       "100.0000          0.78924        0.791840  0.819202  0.821361        0.822561   \n",
       "1000.0000         0.78924        0.791840  0.819202  0.821361        0.822561   \n",
       "10000.0000        0.78924        0.791840  0.819202  0.821361        0.822561   \n",
       "\n",
       "            precision_train  recall_test  recall_train  \n",
       "C-value                                                 \n",
       "0.0001             0.824543     0.799604      0.800516  \n",
       "0.0010             0.825573     0.813205      0.815645  \n",
       "0.0100             0.824126     0.815734      0.818315  \n",
       "0.1000             0.823793     0.815939      0.818999  \n",
       "1.0000             0.823759     0.815870      0.819022  \n",
       "10.0000            0.823755     0.815870      0.818999  \n",
       "100.0000           0.823736     0.815870      0.818999  \n",
       "1000.0000          0.823736     0.815870      0.818999  \n",
       "10000.0000         0.823736     0.815870      0.818999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.25)\n",
    "imp_median_X = SimpleImputer(missing_values=np.nan, strategy='median').fit(X_train)\n",
    "X_train = imp_median_X.transform(X_train)\n",
    "X_test = imp_median_X.transform(X_test)\n",
    "\n",
    "imp_median_y = SimpleImputer(missing_values=np.nan, strategy='median').fit(y_train)\n",
    "y_train = imp_median_y.transform(y_train)\n",
    "y_test = imp_median_y.transform(y_test)\n",
    "\n",
    "# fit scaler and scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "def compute_scores(X_train,X_test,y_train,y_test, C):\n",
    "    # fit logistic regression model\n",
    "    logreg = LogisticRegression(C=C, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "    # predict y for train set\n",
    "    pred_train = logreg.predict(X_train).tolist()\n",
    "    # predict y for test set\n",
    "    pred_test = logreg.predict(X_test).tolist()\n",
    "            \n",
    "    # calculate evaluation measures\n",
    "    evaluation_measures = dict()\n",
    "    evaluation_measures['accuracy_train'] = accuracy(y_train, pred_train)\n",
    "    evaluation_measures['accuracy_test'] = accuracy(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['precision_train'] = precision(y_train, pred_train)\n",
    "    evaluation_measures['precision_test'] = precision(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['recall_train'] = recall(y_train, pred_train)\n",
    "    evaluation_measures['recall_test'] = recall(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['f1_train'] = f1(y_train, pred_train)\n",
    "    evaluation_measures['f1_test'] = f1(y_test, pred_test)\n",
    "    \n",
    "    return evaluation_measures\n",
    "\n",
    "# for power in [1, 2]:\n",
    "#     X_train_poly = polynomial(X_train, power)\n",
    "#     X_test_poly = polynomial(X_test, power)\n",
    "# # Scale all features using the RobustScaler\n",
    "# scaler = RobustScaler().fit(X_train_poly)\n",
    "# X_train_scaled = scaler.transform(X_train_poly)\n",
    "# X_test_scaled = scaler.transform(X_test_poly)\n",
    "C = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 1e2, 1e3, 1e4]\n",
    "measures = pd.DataFrame()\n",
    "for c in C:\n",
    "    em = compute_scores(X_train_scaled,X_test_scaled,y_train,y_test, c)\n",
    "    em = pd.Series(em)\n",
    "    measures = measures.append(em, ignore_index=True)\n",
    "measures.index = C\n",
    "measures.index = measures.index.rename('C-value')\n",
    "display(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35895,  7679],\n",
       "       [23498,  7928]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "pred_train = logreg.predict(X_train).tolist()\n",
    "contigency_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8005857142857142\n",
      "Testing accuracy: 0.7920333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)\n",
    "transformer = RobustScaler().fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(8, 8), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'Training accuracy: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing accuracy: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_id', 'backers_count', 'blurb', 'category',\n",
       "       'converted_pledged_amount', 'country', 'created_at', 'currency',\n",
       "       'deadline', 'fx_rate', 'goal', 'launched_at', 'name', 'pledged',\n",
       "       'staff_pick', 'usd_pledged', 'location', 'funded', 'subcategory',\n",
       "       'project_url', 'reward_url', 'continent', 'rate_funded_cat',\n",
       "       'rate_funded_country', 'rate_funded_continent', 'rate_funded_sub',\n",
       "       'delta_time_created', 'delta_time_launched', 'delta_time_launched_days',\n",
       "       'delta_time_created_days', 'goal_converted_log', 'goal_per_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
