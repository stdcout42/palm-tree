{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('KS_train_data.csv', delimiter=',')\n",
    "#df_test = pd.read_csv('KS_test_data.csv', delimiter=';')\n",
    "# X = df.loc[:,'f1':'f100'].values\n",
    "# y = [ bool(y) for y in df.loc[:,'loss'].values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country = df.country.fillna('NA')\n",
    "EU = ('GB', 'ES', 'FR', 'IT', 'NL', 'IS', 'CZ', 'FI', 'DE', 'IE', 'SJ', 'DK', 'SE', 'HU', 'NO', 'CY', 'CH', 'BE', \n",
    "          'LV', 'UA', 'AT', 'SI', 'LT', 'RO', 'RU', 'AX', 'MC', 'PT', 'GL', 'GR', 'SK', 'EE', 'BA', 'ME', 'LU', 'RS',\n",
    "         'PL', 'MD', 'BG', 'HR', 'MK', 'BY', 'XK', 'FO', 'MT')\n",
    "NA = ('US', 'CA', 'MX', 'CR', 'GT', 'HT', 'AG', 'JM', 'BZ', 'CU', 'SV', 'PR', 'PA', 'NI', 'DO', 'CW', 'VI', 'BB',\n",
    "         'HN', 'LC', 'TT', 'BS', 'GP', 'VC', 'DM')\n",
    "SA = ('AR', 'PE', 'SR', 'BR', 'BO', 'EC', 'CO', 'CL', 'VE', 'PY', 'GY', 'UY')\n",
    "AF = ('KE', 'MW', 'ZA', 'RW', 'LR', 'EG', 'SN', 'NG', 'TZ', 'GH', 'GQ', 'ZM', 'MG', 'ET', 'MA', 'CD', 'BF', 'UG',\n",
    "         'CI', 'DZ', 'ML', 'SD', 'ZW', 'CM', 'TN', 'NE', 'MZ', 'GN', 'SO', 'LY', 'DJ', 'GA', 'SS', 'GM', 'BJ', 'CF',\n",
    "          'CG', 'NA')\n",
    "AS = ('TH', 'ID', 'KH', 'IN', 'JP', 'TR', 'CN', 'MY', 'MN', 'IL', 'KR', 'PH', 'HK', 'SG', 'PS', 'TW', 'NP', 'IR',\n",
    "         'QA', 'VN', 'IQ', 'AE', 'LK', 'GE', 'LB', 'AM', 'KZ', 'AF', 'KP', 'BD', 'PK', 'MM', 'BT', 'JO', 'MV', 'LA',\n",
    "         'KW', 'SY', 'TJ', 'TL', 'YE', 'MO', 'KG')\n",
    "AT = ('AQ')\n",
    "OC = ('AU','NZ', 'PG', 'FJ', 'FM', 'CK', 'GU', 'NC', 'PF', 'VU' )\n",
    "UNK = ('?')\n",
    "def conditions(x):\n",
    "    if x in EU:\n",
    "        return \"EU\"\n",
    "    elif x in NA:\n",
    "        return \"NA\"\n",
    "    elif x in SA:\n",
    "        return \"SA\"\n",
    "    elif x in AF:\n",
    "        return \"AF\"\n",
    "    elif x in AS:\n",
    "        return \"AS\"\n",
    "    elif x in AT:\n",
    "        return \"AT\"\n",
    "    elif x in OC:\n",
    "        return \"OC\"\n",
    "    else:\n",
    "        return \"UNK\"\n",
    "\n",
    "func = np.vectorize(conditions)\n",
    "continents = func(df[\"country\"])\n",
    "df[\"continent\"] = continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_cat = {}\n",
    "funded_in_cat = {}\n",
    "rate_funded_cat = {}\n",
    "for x in df.category.unique():\n",
    "    total_in_cat[x] = df.loc[(df.category == x, 'project_id')].count()\n",
    "    funded_in_cat[x] = df.loc[(df.category == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_cat[x] = funded_in_cat[x] / total_in_cat[x]\n",
    "df['rate_funded_cat'] = df.apply(lambda row: rate_funded_cat[row.category], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-616e9774f863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfunded_in_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunded\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'project_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrate_funded_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunded_in_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_in_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rate_funded_country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrate_funded_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 result = libreduction.compute_reduction(\n\u001b[0m\u001b[1;32m    296\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-616e9774f863>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfunded_in_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunded\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'project_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrate_funded_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunded_in_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_in_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rate_funded_country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrate_funded_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'GB'"
     ]
    }
   ],
   "source": [
    "total_in_country = {}\n",
    "funded_in_country = {}\n",
    "rate_funded_country = {}\n",
    "for x in df.country.unique():\n",
    "    total_in_country[x] = df.loc[(df.country == x, 'project_id')].count()\n",
    "    funded_in_country[x] = df.loc[(df.country == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_country[x] = funded_in_country[x] / total_in_country[x]\n",
    "    df['rate_funded_country'] = df.apply(lambda row: rate_funded_country[row.country], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_continent = {}\n",
    "funded_in_continent = {}\n",
    "rate_funded_continent = {}\n",
    "for x in df.continent.unique():\n",
    "    total_in_continent[x] = df.loc[(df.continent == x, 'project_id')].count()\n",
    "    funded_in_continent[x] = df.loc[(df.continent == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_continent[x] = funded_in_continent[x] / total_in_continent[x]\n",
    "df['rate_funded_continent'] = df.apply(lambda row: rate_funded_continent[row.continent], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_sub = {}\n",
    "funded_in_sub = {}\n",
    "rate_funded_sub = {}\n",
    "for x in df.subcategory.unique():\n",
    "    total_in_sub[x] = df.loc[(df.subcategory == x, 'project_id')].count()\n",
    "    funded_in_sub[x] = df.loc[(df.subcategory == x) & (df.funded == True), 'project_id'].count() \n",
    "    rate_funded_sub[x] = funded_in_sub[x] / total_in_sub[x]\n",
    "df['rate_funded_sub'] = df.apply(lambda row: rate_funded_sub[row.subcategory], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta_time_created'] = df.deadline - df.created_at\n",
    "df['delta_time_launched'] = df.deadline - df.launched_at\n",
    "df['delta_time_launched_days'] = df.delta_time_launched / 86400\n",
    "df['delta_time_created_days'] = df.delta_time_launched / 86400\n",
    "df['goal_converted_log'] = np.log(df.goal * df.fx_rate)\n",
    "df['goal_per_day'] = df['goal_converted_log'] / df['delta_time_launched']\n",
    "cols = ['rate_funded_sub','rate_funded_continent', 'rate_funded_cat', \n",
    "        'delta_time_launched_days', 'goal_converted_log', 'staff_pick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_id', 'backers_count', 'blurb', 'category',\n",
       "       'converted_pledged_amount', 'country', 'created_at', 'currency',\n",
       "       'deadline', 'fx_rate',\n",
       "       ...\n",
       "       'tour', 'up', 'us', 'video', 'we', 'web', 'with', 'world', 'you',\n",
       "       'your'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy as sp\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.max_features = 100\n",
    "vectorizer.max_df = .3\n",
    "\n",
    "X = vectorizer.fit_transform(new_df.name.astype('U')) \n",
    "count_vect_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n",
    "new_df = pd.concat([new_df, count_vect_df], axis=1)\n",
    "new_df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vectorizer.get_feature_names():\n",
    "    cols.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[cols]\n",
    "y = new_df['funded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contigency_matrix(true_y, predicted_y):\n",
    "    # YOUR CODE HERE, Create TP, FP, TN, FN\n",
    "    tp=fp=tn=fn=0\n",
    "    for true, pred in zip(true_y, predicted_y):\n",
    "        if pred == True:\n",
    "            if pred == true:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if pred == true:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1      \n",
    "    matrix = np.array(([tp, fp], [tn, fn]))\n",
    "    # Make sure your output fits the following format:\n",
    "    # matrix = np.array(([TP, FP], [TN, FN]))\n",
    "    return matrix\n",
    "\n",
    "def accuracy(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp+fn+tn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "        return accuracy\n",
    "def precision(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fp == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "        return precision\n",
    "def recall(true_y, predicted_y):\n",
    "    matrix = contigency_matrix(true_y, predicted_y)\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    tn = matrix[1][0]\n",
    "    fn = matrix[1][1]\n",
    "    if tp+fn == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "        return recall\n",
    "def f1(true_y, predicted_y):\n",
    "    precision_v = precision(true_y, predicted_y)\n",
    "    recall_v = recall(true_y, predicted_y)\n",
    "    if precision_v+recall_v == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        f1 = 2*((precision_v*recall_v)/(precision_v+recall_v))\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(X, degree):\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    ### END SOLUTION\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>recall_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.78364</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.813386</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>0.826069</td>\n",
       "      <td>0.824660</td>\n",
       "      <td>0.801087</td>\n",
       "      <td>0.798189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.79096</td>\n",
       "      <td>0.790933</td>\n",
       "      <td>0.820954</td>\n",
       "      <td>0.819471</td>\n",
       "      <td>0.827817</td>\n",
       "      <td>0.825382</td>\n",
       "      <td>0.814203</td>\n",
       "      <td>0.813645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.79120</td>\n",
       "      <td>0.791680</td>\n",
       "      <td>0.821746</td>\n",
       "      <td>0.820665</td>\n",
       "      <td>0.825863</td>\n",
       "      <td>0.824032</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.817325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.79076</td>\n",
       "      <td>0.791733</td>\n",
       "      <td>0.821535</td>\n",
       "      <td>0.820814</td>\n",
       "      <td>0.824884</td>\n",
       "      <td>0.823705</td>\n",
       "      <td>0.818213</td>\n",
       "      <td>0.817943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.79072</td>\n",
       "      <td>0.791680</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.820764</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>0.823674</td>\n",
       "      <td>0.818145</td>\n",
       "      <td>0.817874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>0.79072</td>\n",
       "      <td>0.791680</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.820764</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>0.823674</td>\n",
       "      <td>0.818145</td>\n",
       "      <td>0.817874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>0.79072</td>\n",
       "      <td>0.791680</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.820764</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>0.823674</td>\n",
       "      <td>0.818145</td>\n",
       "      <td>0.817874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>0.79072</td>\n",
       "      <td>0.791680</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.820764</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>0.823674</td>\n",
       "      <td>0.818145</td>\n",
       "      <td>0.817874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0000</th>\n",
       "      <td>0.79072</td>\n",
       "      <td>0.791680</td>\n",
       "      <td>0.821494</td>\n",
       "      <td>0.820764</td>\n",
       "      <td>0.824872</td>\n",
       "      <td>0.823674</td>\n",
       "      <td>0.818145</td>\n",
       "      <td>0.817874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy_test  accuracy_train   f1_test  f1_train  precision_test  \\\n",
       "C-value                                                                         \n",
       "0.0001            0.78364        0.783333  0.813386  0.811209        0.826069   \n",
       "0.0010            0.79096        0.790933  0.820954  0.819471        0.827817   \n",
       "0.0100            0.79120        0.791680  0.821746  0.820665        0.825863   \n",
       "0.1000            0.79076        0.791733  0.821535  0.820814        0.824884   \n",
       "1.0000            0.79072        0.791680  0.821494  0.820764        0.824872   \n",
       "10.0000           0.79072        0.791680  0.821494  0.820764        0.824872   \n",
       "100.0000          0.79072        0.791680  0.821494  0.820764        0.824872   \n",
       "1000.0000         0.79072        0.791680  0.821494  0.820764        0.824872   \n",
       "10000.0000        0.79072        0.791680  0.821494  0.820764        0.824872   \n",
       "\n",
       "            precision_train  recall_test  recall_train  \n",
       "C-value                                                 \n",
       "0.0001             0.824660     0.801087      0.798189  \n",
       "0.0010             0.825382     0.814203      0.813645  \n",
       "0.0100             0.824032     0.817669      0.817325  \n",
       "0.1000             0.823705     0.818213      0.817943  \n",
       "1.0000             0.823674     0.818145      0.817874  \n",
       "10.0000            0.823674     0.818145      0.817874  \n",
       "100.0000           0.823674     0.818145      0.817874  \n",
       "1000.0000          0.823674     0.818145      0.817874  \n",
       "10000.0000         0.823674     0.818145      0.817874  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.25)\n",
    "imp_median_X = SimpleImputer(missing_values=np.nan, strategy='median').fit(X_train)\n",
    "X_train = imp_median_X.transform(X_train)\n",
    "X_test = imp_median_X.transform(X_test)\n",
    "\n",
    "imp_median_y = SimpleImputer(missing_values=np.nan, strategy='median').fit(y_train)\n",
    "y_train = imp_median_y.transform(y_train)\n",
    "y_test = imp_median_y.transform(y_test)\n",
    "\n",
    "# fit scaler and scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "def compute_scores(X_train,X_test,y_train,y_test, C):\n",
    "    # fit logistic regression model\n",
    "    logreg = LogisticRegression(C=C, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "    # predict y for train set\n",
    "    pred_train = logreg.predict(X_train).tolist()\n",
    "    # predict y for test set\n",
    "    pred_test = logreg.predict(X_test).tolist()\n",
    "            \n",
    "    # calculate evaluation measures\n",
    "    evaluation_measures = dict()\n",
    "    evaluation_measures['accuracy_train'] = accuracy(y_train, pred_train)\n",
    "    evaluation_measures['accuracy_test'] = accuracy(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['precision_train'] = precision(y_train, pred_train)\n",
    "    evaluation_measures['precision_test'] = precision(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['recall_train'] = recall(y_train, pred_train)\n",
    "    evaluation_measures['recall_test'] = recall(y_test, pred_test)\n",
    "    \n",
    "    evaluation_measures['f1_train'] = f1(y_train, pred_train)\n",
    "    evaluation_measures['f1_test'] = f1(y_test, pred_test)\n",
    "    \n",
    "    return evaluation_measures\n",
    "\n",
    "# for power in [1, 2]:\n",
    "#     X_train_poly = polynomial(X_train, power)\n",
    "#     X_test_poly = polynomial(X_test, power)\n",
    "# # Scale all features using the RobustScaler\n",
    "# scaler = RobustScaler().fit(X_train_poly)\n",
    "# X_train_scaled = scaler.transform(X_train_poly)\n",
    "# X_test_scaled = scaler.transform(X_test_poly)\n",
    "C = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 1e2, 1e3, 1e4]\n",
    "measures = pd.DataFrame()\n",
    "for c in C:\n",
    "    em = compute_scores(X_train_scaled,X_test_scaled,y_train,y_test, c)\n",
    "    em = pd.Series(em)\n",
    "    measures = measures.append(em, ignore_index=True)\n",
    "measures.index = C\n",
    "measures.index = measures.index.rename('C-value')\n",
    "display(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35779,  7661],\n",
       "       [23600,  7960]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, solver='liblinear').fit(X_train,y_train.ravel())\n",
    "pred_train = logreg.predict(X_train).tolist()\n",
    "contigency_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7980714285714285\n",
      "Testing accuracy: 0.7897666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)\n",
    "transformer = RobustScaler().fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-2, hidden_layer_sizes=(5, 5), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'Training accuracy: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing accuracy: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_f1_macro', 'train_f1_macro', 'test_accuracy', 'train_accuracy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "mlp = make_pipeline(RobustScaler(), MLPClassifier(solver='adam', alpha=1e-2, hidden_layer_sizes=(4,4), random_state=1))\n",
    "scores = cross_validate(mlp, X, y, cv=5, scoring=['f1_macro', 'accuracy'], return_train_score=True)\n",
    "scores.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
